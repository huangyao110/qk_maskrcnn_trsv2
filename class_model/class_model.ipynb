{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitDataSet(object):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    '''\n",
    "    这个是用于分类数据集的，即随机选择一定比例的图片，\n",
    "    用于训练和验证；\n",
    "    arg: data_dir: 分类数据集的路径\n",
    "    '''\n",
    "        \n",
    "    def read_all_pic(self):\n",
    "        ntxt, n2txt = ntxt.txt, n2txt.txt\n",
    "        for root, dirs, _ in os.walk(self.data_dir):\n",
    "            if dirs == 'reshape-2n':\n",
    "                root_2n_path = os.path.join(root, dirs)\n",
    "                n2_files = [os.path.join(root_2n_path, n2) for n2 in os.listdir(root_n_path)]\n",
    "                with open(n2txt, 'w') as f:\n",
    "                    for file in n_files:\n",
    "                        f.write(file + '\\n')\n",
    "            if dirs == 'reshape-n':\n",
    "                root_n_path = os.path.join(root, dirs)\n",
    "                n_files = [os.path.join(root_n_path, n) for n in os.listdir(root_n_path)]\n",
    "                with open(ntxt, 'w') as f:\n",
    "                    for file in n_files:\n",
    "                        f.write(file + '\\n')\n",
    "                \n",
    "    def splitdata(self, ntxt, n2txt, ratio):\n",
    "        with open(ntxt, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        with open(n2txt, 'r') as f:\n",
    "            lines2 = f.readlines()\n",
    "        n_files_train_num = int((len(lines) * ratio)//1)\n",
    "        n2_files_train_num = int((len(lines2) * ratio)//1)\n",
    "        n_files_train = random.sample(lines, n_files_train_num)\n",
    "        n2_files_train = random.sample(lines2, n2_files_train_num)\n",
    "        n_files_val = [line for line in lines if line not in n_files_train]\n",
    "        n2_files_val = [line for line in lines2 if line not in n2_files_train]\n",
    "        assert len(n_files_train) + len(n2_files_train) + \\\n",
    "            len(n_files_val) + len(n2_files_val) == len(lines) + len(lines2), \\\n",
    "            'The number of training and validation files do not match.'\n",
    "        return n_files_train, n2_files_train, n_files_val, n2_files_val\n",
    "    \n",
    "    def split_train_val_2dir(self, root, ntxt, n2txt, ratio):\n",
    "        n_files_train, n2_files_train, n_files_val, n2_files_val = self.splitdata(\n",
    "            ntxt, n2txt, ratio)\n",
    "        for i in range(len(n_files_train)):\n",
    "            shutil.copy(n_files_train[i].strip(), root + 'train/n/')\n",
    "        for train_2n_file in n2_files_train:\n",
    "            shutil.copy(train_2n_file.strip(), root + 'train/2n/')\n",
    "        for val_2n_file in n2_files_val:\n",
    "            shutil.copy(val_2n_file.strip(), root + 'val/2n/')\n",
    "        for val_n_file in n_files_val:\n",
    "            shutil.copy(val_n_file.strip(), root + 'val/n/')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SplitDataSet(data_dir=r'./qk_data/class_data/').split_train_val_2dir(\n",
    "#                         root=r'./qk_data/class_data/',\n",
    "#                          ntxt='./n.txt',n2txt='./2n.txt', ratio=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import pandas as pd\n",
    "\n",
    "# 定义数据集路径和预处理方法\n",
    "data_dir = './qk_data/class_data'\n",
    "train_dir = data_dir + '/train'\n",
    "val_dir = data_dir + '/val'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# 定义训练集、验证集和测试集\n",
    "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# 训练模型\n",
    "def train_model(epochs, model, train_loader, val_loader, csv_name, lr=.01, mt=.0009):\n",
    "    criterion = nn.CrossEntropyLoss(reduce='mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=mt)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    running_loss = []\n",
    "    acc = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, train_loss / 100))\n",
    "        running_loss.append(train_loss / i+1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            vloss = 0\n",
    "            for data in val_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                l = criterion(outputs, labels)\n",
    "                vloss += l.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "            acc.append(100 * correct / total)\n",
    "            val_loss.append(vloss / i+1)\n",
    "    df_loss = pd.DataFrame(running_loss)\n",
    "    df_acc = pd.DataFrame(acc)  \n",
    "    df_vloss = pd.DataFrame(val_loss)\n",
    "    df_acc.to_csv(csv_name + '_acc.csv', index=False)\n",
    "    df_loss.to_csv(csv_name + '_loss.csv', index=False)\n",
    "    df_vloss.to_csv(csv_name + '_vloss.csv', index=False)\n",
    "    return running_loss, acc, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义r50模型\n",
    "model_r50 = models.resnet50(pretrained=True)\n",
    "num_features = model_r50.fc.in_features\n",
    "model_r50.fc = nn.Linear(num_features, 2) # 分类器,2表示n和2n\n",
    "\n",
    "# 定义r34模型\n",
    "model_r34 = models.resnet34(pretrained=True)\n",
    "num_features = model_r34.fc.in_features\n",
    "model_r34.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "# 定义Vgg16模型\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "model_vgg16.classifier.add_module('qk_classier', nn.Linear(1000, 2))\n",
    "\n",
    "# 定义mobilenet_v3_Large模型\n",
    "model_mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "model_mobilenet_v3_large.classifier.add_module('qk_classier', nn.Linear(1000, 2))\n",
    "\n",
    "# 定义efficient_b0模型\n",
    "\n",
    "model_efficient_b0 = models.efficientnet_b0(pretrained=True)\n",
    "model_efficient_b0.classifier.add_module('qk_classier', nn.Linear(1000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16477\\anaconda3\\envs\\hy-dl\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 68 %\n",
      "Accuracy of the network on the test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "# train_model(model=model_mobilenet_v3_large, epochs=2, train_loader=train_loader, \n",
    "#              val_loader=val_loader, lr=0.001, mt=0.009, csv_name='mobilenet_v3_large');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
